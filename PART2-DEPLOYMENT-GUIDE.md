# ğŸš€ PART 2: Complete MLOps Deployment Guide

**Prerequisites:** âœ… Infrastructure successfully deployed (PART 1 completed)

Your infrastructure outputs:
```
api_ecr_repository_url = "911167906047.dkr.ecr.us-east-1.amazonaws.com/abalone-prediction-api"
eks_cluster_name = "abalone-mlops"
github_actions_role_arn = "arn:aws:iam::911167906047:role/GitHubActionRole"
sagemaker_role_arn = "arn:aws:iam::911167906047:role/SageMakerExecutionRole"
ui_ecr_repository_url = "911167906047.dkr.ecr.us-east-1.amazonaws.com/abalone-prediction-ui"
```

---

## ğŸ“‹ **What You'll Deploy:**

1. **MLflow Tracking Server** â†’ Experiment tracking & model registry
2. **SageMaker ML Pipeline** â†’ Train XGBoost model on Abalone dataset  
3. **FastAPI Application** â†’ REST API for model predictions
4. **Streamlit UI** â†’ Web interface for users
5. **Complete automation** â†’ End-to-end MLOps workflow

---

## ğŸ¯ **STEP 1: Deploy MLflow Tracking Server**

### **1.1 Run the MLflow Deployment Workflow**

1. **Go to your GitHub repository**
2. **Click the "Actions" tab**
3. **Find "Deploy MLflow to EKS" workflow**
4. **Click "Run workflow" button (top right)**
5. **Ensure checkbox is checked: "Deploy MLflow to EKS cluster"**
6. **Click green "Run workflow" button**

### **1.2 Monitor the Deployment (5-10 minutes)**

Watch the workflow progress:
- âœ… Configure kubectl for EKS
- âœ… Get database connection details
- âœ… Deploy MLflow using Helm
- âœ… Create LoadBalancer service

### **1.3 Get MLflow URL**

Look for this output in the workflow logs:
```
ğŸ‰ MLflow deployed successfully!
ğŸŒ MLflow URL: http://a1234567890abcdef-1234567890.us-east-1.elb.amazonaws.com
ğŸ“Š Access your MLflow UI at: http://a1234567890abcdef-1234567890.us-east-1.elb.amazonaws.com
```

**âš ï¸ IMPORTANT:** Copy this MLflow URL - you'll need it for the next step!

---

## ğŸ¯ **STEP 2: Add Required GitHub Secrets**

### **2.1 Go to Repository Settings**

1. **Click "Settings" tab** in your GitHub repository
2. **Click "Secrets and variables"** in left sidebar
3. **Click "Actions"**
4. **Click "New repository secret"**

### **2.2 Add These Secrets (One by One):**

**Secret 1: AWS_ACCOUNT_ID**
- Name: `AWS_ACCOUNT_ID`
- Value: `911167906047`

**Secret 2: MLFLOW_TRACKING_URI**
- Name: `MLFLOW_TRACKING_URI`  
- Value: `http://YOUR_MLFLOW_URL_FROM_STEP_1`
- Example: `http://a1234567890abcdef-1234567890.us-east-1.elb.amazonaws.com`

**Secret 3: SAGEMAKER_ROLE_ARN**
- Name: `SAGEMAKER_ROLE_ARN`
- Value: `arn:aws:iam::911167906047:role/SageMakerExecutionRole`

**Secret 4: MODEL_PACKAGE_GROUP_NAME**
- Name: `MODEL_PACKAGE_GROUP_NAME`
- Value: `AbaloneModelPackageGroup`

### **2.3 Verify Secrets**

You should now have these secrets:
- âœ… `AWS_REGION` (from PART 1)
- âœ… `AWS_ACCOUNT_ID` (new)
- âœ… `MLFLOW_TRACKING_URI` (new)
- âœ… `SAGEMAKER_ROLE_ARN` (new)
- âœ… `MODEL_PACKAGE_GROUP_NAME` (new)
- âœ… `GITHUB_ACTIONS_ROLE_ARN` (from PART 1)
- âœ… Other secrets from PART 1

---

## ğŸ¯ **STEP 3: Run ML Pipeline to Train Model**

### **3.1 Run the ML Pipeline Workflow**

1. **Go to "Actions" tab**
2. **Find "ML Pipeline - Train and Register Model" workflow**
3. **Click "Run workflow"**
4. **Optional: Change experiment name** (default: "abalone-age-prediction")
5. **Click green "Run workflow" button**

### **3.2 Monitor ML Pipeline (15-20 minutes)**

The workflow will:
- âœ… Set up Python environment
- âœ… Install ML dependencies  
- âœ… Execute SageMaker pipeline
- âœ… Download Abalone dataset
- âœ… Train XGBoost model
- âœ… Log metrics to MLflow
- âœ… Register model (if performance is good)

### **3.3 Check Results**

**In MLflow UI:**
1. **Open your MLflow URL** from Step 1
2. **Click "Experiments"** 
3. **You should see "abalone-age-prediction" experiment**
4. **Click on the experiment to see runs and metrics**

**Expected metrics:**
- MAE (Mean Absolute Error)
- RMSE (Root Mean Square Error)
- RÂ² Score

---

## ğŸ¯ **STEP 4: Deploy Applications (API + UI)**

### **4.1 Run the Application Deployment Workflow**

1. **Go to "Actions" tab**
2. **Find "Deploy Applications to EKS" workflow**
3. **Click "Run workflow"**
4. **Ensure checkbox is checked: "Deploy API and UI applications"**
5. **Click green "Run workflow" button**

### **4.2 Monitor Deployment (10-15 minutes)**

The workflow will:
- âœ… Build API Docker image
- âœ… Build UI Docker image  
- âœ… Push images to ECR
- âœ… Deploy API to EKS
- âœ… Deploy UI to EKS
- âœ… Create LoadBalancer services

### **4.3 Get Application URLs**

Look for this output in the workflow logs:
```
ğŸ”— Application URLs (may take 2-3 minutes for LoadBalancers):
ğŸ”Œ API URL: http://api-loadbalancer-url.us-east-1.elb.amazonaws.com
ğŸ–¥ï¸ UI URL: http://ui-loadbalancer-url.us-east-1.elb.amazonaws.com
```

**âš ï¸ IMPORTANT:** Copy these URLs - these are your live applications!

---

## ğŸ¯ **STEP 5: Test Your Complete MLOps System**

### **5.1 Test MLflow UI**
1. **Open MLflow URL** from Step 1
2. **Verify you can see experiments and models**
3. **Check that your model training run is logged**

### **5.2 Test API**

**Option A: Using curl**
```bash
curl -X POST "http://YOUR_API_URL/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "length": 0.455,
    "diameter": 0.365,
    "height": 0.095,
    "whole_weight": 0.514,
    "shucked_weight": 0.2245,
    "viscera_weight": 0.101,
    "shell_weight": 0.15,
    "sex": "M"
  }'
```

**Expected Response:**
```json
{
  "prediction": 8.5,
  "model_version": "1",
  "prediction_id": "abc123"
}
```

**Option B: API Documentation**
1. **Open** `http://YOUR_API_URL/docs`
2. **Try the /predict endpoint** with sample data

### **5.3 Test Streamlit UI**
1. **Open UI URL** from Step 4
2. **Enter abalone measurements** in the form
3. **Click "Predict Age"**
4. **Verify you get a prediction result**

---

## ğŸ¯ **STEP 6: Verify Complete Workflow**

### **6.1 End-to-End Flow Check**

âœ… **Data Pipeline**: Automatic data download and preprocessing  
âœ… **Model Training**: XGBoost trained in SageMaker  
âœ… **Experiment Tracking**: Metrics logged in MLflow  
âœ… **Model Registry**: Model registered and versioned  
âœ… **API Deployment**: REST API serving predictions  
âœ… **UI Deployment**: Web interface for users  
âœ… **Infrastructure**: Everything running on AWS EKS  

### **6.2 Key URLs Summary**

**Copy these for your records:**
```
MLflow UI:     http://YOUR_MLFLOW_URL
API Endpoint:  http://YOUR_API_URL
API Docs:      http://YOUR_API_URL/docs  
Streamlit UI:  http://YOUR_UI_URL
```

---

## ğŸ”§ **Troubleshooting**

### **Common Issues:**

**1. MLflow URL not working**
- Wait 2-3 minutes for LoadBalancer
- Check workflow logs for errors
- Verify EKS cluster is running

**2. Application URLs showing "Pending"**
- LoadBalancers take 2-3 minutes to provision
- Check deployment status in workflow logs

**3. API returning errors**
- Check if model was registered in MLflow
- Verify API logs: workflow will show pod status

**4. Secrets not working**
- Double-check secret names (case-sensitive)
- Ensure MLflow URL includes `http://`

### **Useful Commands (if needed):**
```bash
# Check all services
kubectl get svc --all-namespaces

# Check pod status  
kubectl get pods

# Get service URLs
kubectl get svc abalone-api
kubectl get svc abalone-ui
kubectl get svc mlflow -n mlflow
```

---

## ğŸ‰ **SUCCESS! Your MLOps Platform is Live**

You now have a complete, production-ready MLOps platform:

### **ğŸ—ï¸ Infrastructure:**
- âœ… EKS Kubernetes cluster
- âœ… RDS PostgreSQL database
- âœ… ECR container repositories
- âœ… IAM roles and permissions

### **ğŸ¤– ML Platform:**
- âœ… MLflow for experiment tracking
- âœ… SageMaker for ML pipelines
- âœ… XGBoost model trained and registered
- âœ… Automated model versioning

### **ğŸš€ Applications:**
- âœ… FastAPI for model inference
- âœ… Streamlit UI for user interaction
- âœ… LoadBalancer services for external access
- âœ… Container orchestration with Kubernetes

### **âš™ï¸ Automation:**
- âœ… GitHub Actions CI/CD pipelines
- âœ… Automated model training
- âœ… Automated application deployment
- âœ… Infrastructure as Code

### **ğŸ“Š Monitoring:**
- âœ… Experiment tracking in MLflow
- âœ… Model performance metrics
- âœ… Application logs in Kubernetes
- âœ… AWS CloudWatch integration

---

## ğŸ¯ **What's Next?**

Your MLOps platform is ready for:
1. **Adding new models** - Modify pipeline for different datasets
2. **Scaling applications** - Increase replicas in Kubernetes
3. **Adding monitoring** - Set up alerts and dashboards
4. **Implementing A/B testing** - Deploy multiple model versions
5. **Adding data pipelines** - Connect to real data sources

**Congratulations! You've built a complete, enterprise-grade MLOps platform! ğŸš€** 